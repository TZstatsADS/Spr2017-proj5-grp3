---
title: "Fragile Families Challenge"
author: "Yue Gao"
date: "2017/04/27"
output:
  html_notebook: default
  pdf_document: default
  word_document: default
---


Fragile Families Challenge is a scientific mass collaboration combining:
predictive modeling
causal inference
and qualitative interviews 
to improve the lives of disadvantaged children in the US. 


Key research question:  What can be done to improve the life chances of disadvantaged children? 
Social Scientists <--> Data Scientists 



#Data

Continuous outcomes: 
GPA, Grit, Material hardship

Binary outcomes:
Housing eviction,
Layoff of a caregiver,
Job training for a caregiver 



Assumption:
Age 9 data has already included all the information from age 0-5

```{r, include=FALSE}
library(data.table)
library(stringr)
library(dmm)
library(Hmisc)

setwd("~/GitHub/Spr2017-proj5-grp3/")
load("../data/background.RData")
source("../lib/helper_data.R")
#background=read.csv("~/Documents/FFChallenge/background.csv",header=TRUE)

features<-colnames(background)

#create codebook
codebooks<-c("child","mom","dad","teacher")
data.info<-vector()

for (i in codebooks){
feat.table<-read.csv(paste0(".../data/codebook/ff_",i,"_cb9.csv"),header=FALSE)
feat.table<-feat.table[,-1]
feat.table<-feat.table[-1,]
feat.table<-cbind(rep(i,nrow(feat.table)),feat.table)
data.info<-rbind(data.info,feat.table)
}

colnames(data.info)<-c("class","code","description")
data.info=as.data.frame(data.info)
featnum<-nrow(data.info)

extract.feature<-features %in% data.info$code  
sum(extract.feature)


extract.data<-background[,extract.feature]
extract.data<-cbind(challengeID=background[,1],extract.data)

write.csv(extract.data,file="../data/extract_data.csv")
save(data.info, file="../data/data_info.RData")
```

[data1](~/GitHub/Spr2017-proj5-grp3/figs/140.pic.jpg)


[data2](~/GitHub/Spr2017-proj5-grp3/figs/160.pic.jpg)

Step 1: clean data

 Several missing value codes:
 -9 Not in wave 
 -6 Valid skip 
 -2 Dont know 
 -1 Refuse 
 NA also used occasionally 

 Categorical feature:
Make NA a special level


```{r, message=FALSE, warning=FALSE}
#remove columns with missing values more than 80%
extract.data<-read.csv("../data/extract_data.csv")

ED<-divide.data(extract.data)
ED.categorical=ED[[1]]
ED.continuous=ED[[2]]

categorical=colnames(ED.categorical)

ED.factor=clean.factor(ED.continuous)

ED.continuous=ED.continuous[,!colnames(ED.continuous) %in% colnames(ED.factor)]
ED.continuous=clean.continuous(ED.continuous)

categorical=c(categorical,colnames(ED.factor[,grep("*isna",colnames(ED.factor))]),colnames(ED.continuous[,grep("*isna",colnames(ED.continuous))]))
#combine the data

ED.final<-cbind(ED.continuous,ED.categorical,ED.factor)

ED.final=as.data.frame(ED.final)

```



Step 2: solving missing data problem

Continuous feature:
Create a dummy variable indicating the missing situation of the feature
Impute the missing value with median


```{r}

final.mis<-ED.final[,which(unlist(lapply(ED.final, function(x) anyNA(x))))]
missing=colnames(final.mis)

for(i in missing)
{
  ED.final[,i] = impute(ED.final[,i], fun = median)  
}

write.csv(ED.final,file="../data/NAreplaced.csv")
save(categorical, file="../data/categorical.RData")
```




Step 3: feature selection

Firstly, it adds randomness to the given data set by creating shuffled copies of all features (which are called shadow features).

Then, it trains a random forest classifier on the extended data set and applies a feature importance measure (the default is Mean Decrease Accuracy) to evaluate the importance of each feature where higher means more important.

At every iteration, it checks whether a real feature has a higher importance than the best of its shadow features (i.e. whether the feature has a higher Z score than the maximum Z score of its shadow features) and constantly removes features which are deemed highly unimportant.
Finally, the algorithm stops either when all features gets confirmed or rejected or it reaches a specified limit of random forest runs.


```{r, eval=FALSE}
library(Boruta)
load("../doc/data_info.RData")
ED.final<-read.csv("../data/NAreplaced.csv")
#names(ED.final[,1])="challengeID"
label<-read.csv("../data/train.csv")

# label<-label[,1:2] #gpa
# label<-label[,c(1,3)] #grit
# label<-label[,c(1,4)] #materialHardship
label<-label[,c(1,7)] #jobTraining
label=na.omit(label)
Index=ED.final$challengeID %in% label$challengeID

data.train<-ED.final[Index,]
data.train<-as.data.frame(data.train)

model.features = Boruta(data.train[,-1], label$jobTraining, maxRuns = 500)

results = as.data.frame(model.features$finalDecision)
which(results!="Rejected")
Bcodes = rownames(results)[which(results!="Rejected")]

```


What are the descriptions of the features (Boruta)?

```{r}
des = data.frame()
#score = data.frame()
for (i in 1:length(Bcodes))
{
  if(Bcodes[i] %in% data.info$code)
  {
    des = rbind(des, as.data.frame(data.info$description[data.info$code==Bcodes[i]]))
   #score = rbind(score, as.data.frame(imp$meanImp[which(rownames(imp)==Bcodes[i])]))
  }
}

decision = as.data.frame(model.features$finalDecision[model.features$finalDecision!="Rejected"])

Bdf = cbind(Bcodes, des, decision)
colnames(Bdf) = c("Codes", "Description", "Decision")
pred="jobTraining"
write.csv(Bdf, paste0("../data/",pred,"features.csv"), row.names = F)

# write.csv(des, "temp_des.csv", row.names = F)
# des <- read.csv("temp_des.csv")
```


Fit model

# GPA
```{r, message=FALSE, warning=FALSE}
source("../lib/modelFunc.R")
data.filtered <- read.csv('../data/NAreplaced.csv') #4242 1388
select <- read.csv('../data/Updated_Features/gpa_features.csv')
data.filtered <- data.filtered[,select$Codes] # 4242*64

label <- read.csv('../data/train.csv')
label<-na.omit(label)
Index<-data.filtered$challengeID %in% label$challengeID

data.train<-data.filtered[Index,]
data.train<-as.data.frame(data.train)
data.train<-cbind(label$gpa, data.train)
colnames(data.train)[1]<-"gpa"

# create training and test data set
set.seed(123)
train.index <- sample(1:nrow(data.train),800,replace = F)
train <- data.train[train.index,] #800*64
test <- data.train[-train.index,] #214*64

y<-train[,1]
model_selection_con(train[,-1], test, y)
```

# Grit
```{r, message=FALSE, warning=FALSE}
data.filtered <- read.csv('../data/NAreplaced.csv') 
select <- read.csv('../data/Updated_Features/grit_features.csv')
data.filtered <- data.filtered[,select$Codes] 

data.train<-data.filtered[Index,]
data.train<-as.data.frame(data.train)
data.train<-cbind(label$grit, data.train)
colnames(data.train)[1]<-"grit"

# create training and test data set
train.index <- sample(1:nrow(data.train),800,replace = F)
train <- data.train[train.index,] #800*64
test <- data.train[-train.index,] #214*64

y<-train[,1]
model_selection_con(train[,-1], test, y)
```

# materialHardship
```{r, message=FALSE, warning=FALSE}
data.filtered <- read.csv('../data/NAreplaced.csv') 
select <- read.csv('../data/Updated_Features/materialHardship_features.csv')
data.filtered <- data.filtered[,select$Codes] 

data.train<-data.filtered[Index,]
data.train<-as.data.frame(data.train)
data.train<-cbind(label$materialHardship, data.train)
colnames(data.train)[1]<-"materialHardship"

# create training and test data set
train.index <- sample(1:nrow(data.train),800,replace = F)
train <- data.train[train.index,] #800*64
test <- data.train[-train.index,] #214*64

y<-train[,1]
model_selection_con(train[,-1], test, y)
```

# eviction
```{r, message=FALSE, warning=FALSE}
data.filtered <- read.csv('../data/NAreplaced.csv') 
select <- read.csv('../data/Updated_Features/eviction_features.csv')
data.filtered <- data.filtered[,select$Codes] 

data.train<-data.filtered[Index,]
data.train<-as.data.frame(data.train)
data.train<-cbind(label$eviction, data.train)
colnames(data.train)[1]<-"eviction"

# create training and test data set
train.index <- sample(1:nrow(data.train),800,replace = F)
train <- data.train[train.index,] #800*64
test <- data.train[-train.index,] #214*64

y<-factor(train[,1])
model_selection_cat(train[,-1], test, y)
```

# layoff
```{r, message=FALSE, warning=FALSE}
data.filtered <- read.csv('../data/NAreplaced.csv') 
select <- read.csv('../data/Updated_Features/layoff_features.csv')
data.filtered <- data.filtered[,select$Codes] 

data.train<-data.filtered[Index,]
data.train<-as.data.frame(data.train)
data.train<-cbind(label$layoff, data.train)
colnames(data.train)[1]<-"layoff"

# create training and test data set
train.index <- sample(1:nrow(data.train),800,replace = F)
train <- data.train[train.index,] #800*64
test <- data.train[-train.index,] #214*64

y<-factor(train[,1])
model_selection_cat(train[,-1], test, y)
```

# jobTraining
```{r, message=FALSE, warning=FALSE}
data.filtered <- read.csv('../data/NAreplaced.csv') 
select <- read.csv('../data/Updated_Features/jobTraining_features.csv')
data.filtered <- data.filtered[,select$Codes] 

data.train<-data.filtered[Index,]
data.train<-as.data.frame(data.train)
data.train<-cbind(label$jobTraining, data.train)
colnames(data.train)[1]<-"jobTraining"

# create training and test data set
train.index <- sample(1:nrow(data.train),800,replace = F)
train <- data.train[train.index,] #800*64
test <- data.train[-train.index,] #214*64

y<-factor(train[,1])
model_selection_cat(train[,-1], test, y)
```



